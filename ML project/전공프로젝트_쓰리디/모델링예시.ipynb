{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mobilenet.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09aOSQ5AgZrb"
      },
      "source": [
        "function ClickConnect(){\n",
        "    console.log(\"코랩 연결 끊김 방지\"); \n",
        "    document.querySelector(\"colab-toolbar-button#connect\").click() \n",
        "}\n",
        "setInterval(ClickConnect, 60 * 1000)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9vurdCCQgDH"
      },
      "source": [
        "!cp -r '/content/drive/My Drive/tfrecord/train' '/content'\n",
        "# train 데이터 복사\n",
        "!zip -s 0 /content/train/tf_record_train.zip --out train.zip\n",
        "# 분할 압축 파일 합치기\n",
        "!rm -rf /content/train\n",
        "# 분할 압축 파일 제거\n",
        "!unzip /content/train.zip\n",
        "# 압축 해제\n",
        "!rm /content/train.zip\n",
        "# 합친 압축파일 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbA5gjpppHUG"
      },
      "source": [
        "# 위와 동일(Valid set)\n",
        "!cp -r '/content/drive/My Drive/tfrecord/valid' '/content'\n",
        "!zip -s 0 /content/valid/tf_record_val.zip --out val.zip\n",
        "!rm -rf /content/valid\n",
        "!unzip /content/val.zip\n",
        "!rm /content/val.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oum6qCkpKtO_"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tensorflow 관련 라이브러리\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential,Model, load_model\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, BatchNormalization, PReLU\n",
        "from tensorflow.keras.layers import Flatten, Activation, Dense, GlobalAveragePooling2D, Softmax\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow_addons import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx-71ttALYh1"
      },
      "source": [
        "train_tfrecord_path = '/content/tf_record_train.tfrecords'\n",
        "valid_tfrecord_path = '/content/tf_record_val.tfrecords'\n",
        "\n",
        "\n",
        "BUFFER_SIZE = 256\n",
        "BATCH_SIZE = 64\n",
        "NUM_CLASS = 1049\n",
        "\n",
        "\n",
        "image_feature_description = {\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "    'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
        "    # 'id': tf.io.FixedLenFeature([], tf.string),\n",
        "}\n",
        "\n",
        "\n",
        "    \n",
        "def _parse_image_function(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "\n",
        "def map_func(target_record):\n",
        "    img = target_record['image_raw']\n",
        "    label = target_record['randmark_id']\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    if tf.random.uniform([]) > 0.5:\n",
        "        img = tf.image.flip_left_right(img)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    img = tf.dtypes.cast(img, tf.float32)\n",
        "    return img, label\n",
        "\n",
        "def map_func_valid(target_record):\n",
        "    img = target_record['image_raw']\n",
        "    label = target_record['randmark_id']\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.dtypes.cast(img, tf.float32)\n",
        "    return img, label\n",
        "\n",
        "def prep_func(image, label):\n",
        "    result_image = image / 255\n",
        "    result_image = tf.image.resize(result_image, (270,480))\n",
        "    onehot_label = tf.one_hot(label, depth=NUM_CLASS)\n",
        "    return result_image, onehot_label\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
        "dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "valid_dataset = tf.data.TFRecordDataset(valid_tfrecord_path, compression_type='GZIP')\n",
        "valid_dataset = valid_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.map(map_func_valid, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
        "valid_dataset = valid_dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqJi8lJULfXR"
      },
      "source": [
        "earlystop = EarlyStopping(patience=5)\n",
        "learning_rate_reduction=ReduceLROnPlateau(\n",
        "                        monitor= \"val_accuracy\", \n",
        "                        patience = 2, \n",
        "                        factor = 0.5, \n",
        "                        min_lr=1e-7,\n",
        "                        verbose=1)\n",
        "model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장\n",
        "        filepath=\"/content/drive/My Drive/landmark_EFNETB5_model_270_480_radam.h5\", #모델 파일 경로\n",
        "        monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
        "        save_best_only=True)\n",
        "\n",
        "\n",
        "callbacks = [earlystop, learning_rate_reduction, model_check]\n",
        "# callbacks = [earlystop, learning_rate_reduction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43taX2_cLyma"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "mobilenet = MobileNetV2(weights='imagenet', include_top=False, input_shape=(270,480,3))\n",
        "\n",
        "\n",
        "for layer in mobilenet.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "for (i, layer) in enumerate(mobilenet.layers):\n",
        "    print(str(i), layer.__class__.__name__, layer.trainable)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(mobilenet)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1049))\n",
        "model.add(BatchNormalization())\n",
        "model.add(PReLU())\n",
        "model.add(Softmax(dtype='float32', name='softmax'))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(1049, activation='softmax')) \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdaB6AYYhL4Y"
      },
      "source": [
        "from tensorflow.keras.applications import inception_resnet_v2\n",
        "\n",
        "efnet = EfficientNetB5(weights='imagenet' ,include_top=False, input_shape=(270,480,3))\n",
        "for layer in efnet.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "for (i, layer) in enumerate(efnet.layers):\n",
        "    print(str(i), layer.__class__.__name__, layer.trainable)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(efnet)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1049))\n",
        "model.add(PReLU())\n",
        "model.add(Softmax(dtype='float32', name='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZuAoXg3L4Wg"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=optimizers.RectifiedAdam(learning_rate=0.0001),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja3-9rWZMQH7"
      },
      "source": [
        "history = model.fit(dataset,\n",
        "            epochs=1000,  \n",
        "            validation_data=valid_dataset,\n",
        "            callbacks = callbacks,\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qoGIiwBNtmM"
      },
      "source": [
        "class Modeling_process:\n",
        "    \n",
        "    config = {\n",
        "        'image_size' : (270, 480),\n",
        "        'buffer' : 256,\n",
        "        'batch_size' : 32,\n",
        "        'learning_rate' : 0.001,\n",
        "        'activation' : Adam\n",
        "        \n",
        "\n",
        "    }\n",
        "\n",
        "\n",
        "    def __init__(self, train_path, valid_path):\n",
        "        self.train_path = train_path\n",
        "        self.valid_path = valid_path\n",
        "\n",
        "\n",
        "    def preprocessing_data(self, image_size=self.config['image_size'], batch_size=self.config['batch_size'], buffer=self.config['buffer']):\n",
        "        if image_size is None:\n",
        "            image_size = self.config['image_size']\n",
        "\n",
        "        self.dataset = tf.data.TFRecordDataset(self.train_path, compression_type='GZIP')\n",
        "        self.dataset = self.dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.dataset = self.dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.dataset = self.dataset.shuffle(buffer)\n",
        "        self.dataset = self.dataset.batch(batch_size)\n",
        "        self.dataset = self.dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.dataset = self.dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "        self.valid_dataset = tf.data.TFRecordDataset(self.valid_path, compression_type='GZIP')\n",
        "        self.valid_dataset = self.valid_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.valid_dataset = self.valid_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.valid_dataset = self.valid_dataset.batch(batch_size)\n",
        "        self.valid_dataset = self.valid_dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "        self.valid_dataset = self.valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    \n",
        "    def pre_model(self, pre_model, input_shape=self.config['image_size'], include_top=False, learning_rate=self.config['learning_rate'], activation=self.config['activation']):\n",
        "        self.pre_model = pre_model(weights='imagenet', include_top=False, input_shape=(image_size[0],image_size[1],3))\n",
        "        self.model = Sequential()\n",
        "        self.model.add(self.pre_model)\n",
        "        self.model.add(Flatten())\n",
        "        self.model.add(Dense(512, activation='relu', kernel_initializer='he_normal'))\n",
        "        self.model.add(BatchNormalization())\n",
        "        self.model.add(Dropout(0.5))\n",
        "        self.model.add(Dense(1049, activation='softmax')) \n",
        "        \n",
        "        \n",
        "        self.model.compile(loss='categorical_crossentropy',\n",
        "                    optimizer=activation(learning_rate=learning_rate),\n",
        "                    metrics=['accuracy'])\n",
        "        \n",
        "        earlystop = EarlyStopping(patience=5)\n",
        "        learning_rate_reduction=ReduceLROnPlateau(\n",
        "                                monitor= \"val_accuracy\", \n",
        "                                patience = 1, \n",
        "                                factor = 0.5, \n",
        "                                min_lr=0.00001,\n",
        "                                verbose=1)\n",
        "        model_check = ModelCheckpoint( #에포크마다 현재 가중치를 저장\n",
        "                filepath=f\"/content/drive/My Drive/landmark_{pre_model}.h5\", #모델 파일 경로\n",
        "                monitor='val_loss',  # val_loss 가 좋아지지 않으면 모델 파일을 덮어쓰지 않음.\n",
        "                save_best_only=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvrCGPBbMg6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
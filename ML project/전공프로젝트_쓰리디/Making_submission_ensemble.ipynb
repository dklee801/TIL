{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, initializers, regularizers, metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization, Conv2D, Activation , AveragePooling2D , Input ,Dropout\n",
    "from tensorflow.keras.layers import Dense,  MaxPooling2D, Add, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# GPU 설정\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # 특정 GPU에 1GB 메모리만 할당하도록 제한\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[1],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=7048)])\n",
    "    except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 파일을  generator로 예측하신다면 아래 코드 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0/0hmnf5orki.JPG</td>\n",
       "      <td>0hmnf5orki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0/0bgj9co0zl.JPG</td>\n",
       "      <td>0bgj9co0zl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0/03123sl42g.JPG</td>\n",
       "      <td>03123sl42g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0/0vwaki2su2.JPG</td>\n",
       "      <td>0vwaki2su2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0/09jgq862fk.JPG</td>\n",
       "      <td>09jgq862fk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file          id\n",
       "0  0/0hmnf5orki.JPG  0hmnf5orki\n",
       "1  0/0bgj9co0zl.JPG  0bgj9co0zl\n",
       "2  0/03123sl42g.JPG  03123sl42g\n",
       "3  0/0vwaki2su2.JPG  0vwaki2su2\n",
       "4  0/09jgq862fk.JPG  09jgq862fk"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37964, 2)\n"
     ]
    }
   ],
   "source": [
    "# test 데이터 안 '6' 폴더에 있는 체크포인트 오류 데이터 제거 후 실행\n",
    "path = './public'\n",
    "test_dirs = path + '/test'\n",
    "files = []\n",
    "ids=[]\n",
    "for img_cat in os.listdir(test_dirs):\n",
    "    id_dir =  img_cat\n",
    "    for filename in os.listdir(test_dirs + '/' + id_dir):\n",
    "        files.append(id_dir + '/' +filename)\n",
    "        ids.append(filename.split('.JPG')[0])\n",
    "                           \n",
    "test_data = pd.DataFrame(\n",
    "                    {\"file\":files,\n",
    "                    \"id\":ids}\n",
    "                )    \n",
    "\n",
    "display(test_data.head())\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형상 관련 상수 정의 (훈련할때 썼던 이미지 크기 사용)\n",
    "IMAGE_WIDTH=224\n",
    "IMAGE_HEIGHT=224\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNEL=3\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37964 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with tf.device('/device:GPU:0'):\n",
    "    test_datagen=ImageDataGenerator(rescale=1./255) # MinMaxScaling\n",
    "    test_generator=test_datagen.flow_from_dataframe(\n",
    "        test_data,\n",
    "        test_dirs,\n",
    "        x_col= \"file\",\n",
    "        y_col= \"id\",\n",
    "        target_size = IMAGE_SIZE,\n",
    "        class_mode = \"raw\",\n",
    "        batch_size = batch_size,\n",
    "        shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델불러오기\n",
    "with tf.device('/device:GPU:0'):\n",
    "\n",
    "    model = load_model('./landmark_MobileNetv2_model_270_480_radam_2.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=optimizers.RectifiedAdam(),\n",
    "                metrics=['accuracy'])\n",
    "    pred = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'id':test_data['id'].values,\n",
    "                       'landmark_id':np.argmax(pred, axis=1),\n",
    "                       'conf':np.max(pred, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>0.936642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id      conf\n",
       "0  xlf1tgh2ih          956  1.000000\n",
       "1  68a3ot4osk          956  0.999990\n",
       "2  si2lek4u0a          956  0.999785\n",
       "3  rmtqxhipnv          956  0.936642\n",
       "4  2flmjdud0e          956  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + '/sample_submisstion.csv')\n",
    "sub = pd.merge(submission[['id']], pred_df, on='id', how='left')\n",
    "sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(path + '/Densenet.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 테스트 파일을  TFRecord로 예측하신다면 아래 코드 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id      conf\n",
       "0  xlf1tgh2ih          956  0.999983\n",
       "1  68a3ot4osk          956  0.999711\n",
       "2  si2lek4u0a          956  0.999894\n",
       "3  rmtqxhipnv          956  0.999436\n",
       "4  2flmjdud0e          956  0.999974"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    path = './public'\n",
    "    test_tfrecord_path = path + '/tf_record_test.tfrecords'\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_CLASS = 1049\n",
    "    img_size = (331,331) # <- 학습할때 썼던 이미지 사이즈 입력해주세요 !\n",
    "    \n",
    "    image_feature_description_test = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "    def _parse_image_function_test(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, image_feature_description_test)\n",
    "\n",
    "    def map_func_test(target_record):\n",
    "        img = target_record['image_raw']\n",
    "        label = target_record['id']\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.dtypes.cast(img, tf.float32)\n",
    "        return img, label\n",
    "\n",
    "    def prep_func_test(image, label):\n",
    "        result_image = image / 255\n",
    "        result_image = tf.image.resize(result_image, img_size)\n",
    "\n",
    "        return result_image, label\n",
    "\n",
    "    test_dataset = tf.data.TFRecordDataset(test_tfrecord_path, compression_type='GZIP')\n",
    "    test_dataset = test_dataset.map(_parse_image_function_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(map_func_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.map(prep_func_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    \n",
    "    # 모델불러오기\n",
    "    model = load_model('./landmark_inception_resnet_model_299_299_radam_dropout_update.h5', compile=False) # 학습하셨던 모델을 불러와주세요\n",
    "    id_list = []\n",
    "    for _, label in test_dataset:\n",
    "        id_list.extend(list(label))\n",
    "\n",
    "    pred = model.predict(test_dataset)\n",
    "    \n",
    "    pred_df = pd.DataFrame({'id':id_list,\n",
    "                       'landmark_id':np.argmax(pred,axis=1),\n",
    "                       'conf':np.max(pred,axis=1)})\n",
    "    pred_df['id'] = pred_df['id'].apply(lambda x : x.numpy().decode('utf-8'))\n",
    "    \n",
    "    submission = pd.read_csv(path + '/sample_submisstion.csv')\n",
    "    sub = pd.merge(submission[['id']], pred_df, on='id', how='left')\n",
    "    display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(path + '/landmark_inception_resnet_model_299_299_radam_dropout_update.csv', encoding='cp949', index=False) # 저장할 파일 명 정해서 제출파일 만들어주세요~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 앙상블  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = pd.read_csv('./public/mobile_gp_270_480.csv')\n",
    "pred_2 = pd.read_csv('./public/landmark_EFNET5_model_270_480_radam_dropout.csv')\n",
    "pred_3 = pd.read_csv('./public/inception_299_299.csv')\n",
    "pred_4 = pd.read_csv('./public/landmark_inception_resnet_model_299_299_radam_dropout_update.csv')\n",
    "pred_5 = pd.read_csv('./landmark_densenet201_1114.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_id = []\n",
    "conf = []\n",
    "df_dict = {0:pred_1, 1:pred_2, 2: pred_3, 3: pred_4, 4: pred_5}\n",
    "for i in range(len(pred_1)):\n",
    "    max_conf = max([df['conf'][i] for df in df_dict.values()])\n",
    "    max_landmark_df = np.argmax([[df['conf'][i] for df in df_dict.values()]])\n",
    "    max_landmark_id = df_dict[max_landmark_df]['landmark_id'][i]\n",
    "    landmark_id.append(max_landmark_id)\n",
    "    conf.append(max_conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id      conf\n",
       "0  xlf1tgh2ih          956  0.999999\n",
       "1  68a3ot4osk          956  0.999999\n",
       "2  si2lek4u0a          956  0.999998\n",
       "3  rmtqxhipnv          956  1.000000\n",
       "4  2flmjdud0e          956  1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './public'\n",
    "submission = pd.read_csv(path + '/sample_submisstion.csv')\n",
    "submission['landmark_id'] = landmark_id\n",
    "submission['conf'] = conf\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path + '/test_ensemble_5model.csv', encoding='cp949', index=False) # 저장할 파일 명 정해서 제출파일 만들어주세요~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voting + max_ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "landmark_id = []\n",
    "conf = []\n",
    "df_dict = {0:pred_1, 1:pred_2, 2: pred_3, 3: pred_4, 4:pred_5}\n",
    "for i in range(len(pred_1)):\n",
    "    count_id = Counter([df['landmark_id'][i] for df in df_dict.values()])\n",
    "    max_id = max(count_id.items(), key = lambda x: x[1])\n",
    "    if max_id[1] == 1:\n",
    "        max_conf = max([df['conf'][i] for df in df_dict.values()])\n",
    "        max_landmark_df = np.argmax([[df['conf'][i] for df in df_dict.values()]])\n",
    "        max_landmark_id = df_dict[max_landmark_df]['landmark_id'][i]\n",
    "        landmark_id.append(max_landmark_id)\n",
    "        conf.append(max_conf)\n",
    "    else:\n",
    "        landmark_id.append(max_id[0])\n",
    "        conf.append(max([df['conf'][i] for df in df_dict.values() if df['landmark_id'][i]==max_id[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id      conf\n",
       "0  xlf1tgh2ih          956  0.999999\n",
       "1  68a3ot4osk          956  0.999999\n",
       "2  si2lek4u0a          956  0.999998\n",
       "3  rmtqxhipnv          956  1.000000\n",
       "4  2flmjdud0e          956  1.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path + '/sample_submisstion.csv')\n",
    "submission['landmark_id'] = landmark_id\n",
    "submission['conf'] = conf\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(path + '/test_ensemble_voting_max_5model.csv', encoding='cp949', index=False) # 저장할 파일 명 정해서 제출파일 만들어주세요~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model_path, data_path):\n",
    "    model = load_model(model_path,compile=False)\n",
    "    img_size = tuple(model.input.shape[1:3])\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_CLASS = 1049\n",
    "    \n",
    "    image_feature_description_test = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    \n",
    "    }\n",
    "\n",
    "\n",
    "    def _parse_image_function_test(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, image_feature_description_test)\n",
    "\n",
    "    def map_func_test(target_record):\n",
    "        img = target_record['image_raw']\n",
    "        label = target_record['id']\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.dtypes.cast(img, tf.float32)\n",
    "        return img, label\n",
    "\n",
    "    def prep_func_test(image, label):\n",
    "        result_image = image / 255\n",
    "        result_image = tf.image.resize(result_image, img_size)\n",
    "\n",
    "        return result_image, label\n",
    "\n",
    "    test_dataset = tf.data.TFRecordDataset(data_path, compression_type='GZIP')\n",
    "    test_dataset = test_dataset.map(_parse_image_function_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.map(map_func_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "    test_dataset = test_dataset.map(prep_func_test, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    id_list = []\n",
    "    for _, label in test_dataset:\n",
    "        id_list.extend(list(label))\n",
    "\n",
    "    pred = model.predict(test_dataset)\n",
    "    \n",
    "    return id_list, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = prediction('./landmark_MobileNetv2_model_270_480_radam_2.h5','./public/tf_record_test.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_1\n",
      "pred_2\n",
      "pred_3\n",
      "pred_4\n",
      "pred_5\n",
      "pred_6\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    print('pred_1')\n",
    "    id_list, pred_1 = prediction('./landmark_MobileNetv2_model_270_480_radam_2.h5','./public/tf_record_test.tfrecords')\n",
    "    print('pred_2')\n",
    "    _, pred_2 = prediction('./landmark_EFNET5_model_270_480_radam_dropout.h5', './public/tf_record_test.tfrecords')\n",
    "    print('pred_3')\n",
    "    _, pred_3 = prediction('./landamark_inception_model_299_299.h5', './public/tf_record_test.tfrecords')\n",
    "    print('pred_4')\n",
    "    _, pred_4 = prediction('./landmark_inception_resnet_model_299_299_radam_dropout_update.h5', './public/tf_record_test.tfrecords')\n",
    "    print('pred_5')\n",
    "    _, pred_5 = prediction('./landmark_densenet201_270by480_9918.h5', './public/tf_record_test.tfrecords')\n",
    "#     print('pred_6')\n",
    "#     _, pred_6 = prediction('./landmark_NasNet_Large_model_331_331_radam_dropout.h5','./public/tf_record_test.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('pred_1.npy',pred_1)\n",
    "np.save('pred_2.npy',pred_2)\n",
    "np.save('pred_3.npy',pred_3)\n",
    "np.save('pred_4.npy',pred_4)\n",
    "np.save('pred_5.npy',pred_5)\n",
    "np.save('pred_6.npy',pred_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = np.load('./pred_1.npy')\n",
    "pred_2 = np.load('./pred_2.npy')\n",
    "pred_3 = np.load('./pred_3.npy')\n",
    "pred_4 = np.load('./pred_4.npy')\n",
    "pred_5 = np.load('./pred_5.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.5265166e-15, 4.9434663e-18, 1.9810954e-17, ..., 1.0334400e-17,\n",
       "        1.2217659e-17, 3.3298591e-16],\n",
       "       [6.6885886e-11, 3.5676258e-12, 5.5092481e-13, ..., 2.5416981e-13,\n",
       "        2.7326053e-11, 8.6306044e-14],\n",
       "       [5.5723346e-09, 1.8538246e-17, 2.4921706e-15, ..., 7.9169940e-14,\n",
       "        3.1434604e-15, 2.8477790e-14],\n",
       "       ...,\n",
       "       [3.0951910e-10, 4.2182859e-15, 4.5240778e-14, ..., 2.7640436e-13,\n",
       "        7.7156746e-14, 6.8946343e-10],\n",
       "       [2.3851907e-14, 3.4372250e-21, 3.5139145e-17, ..., 2.0842823e-09,\n",
       "        1.5614553e-19, 9.9588213e-19],\n",
       "       [2.2326470e-16, 4.6426410e-20, 1.4189071e-17, ..., 2.3009171e-14,\n",
       "        3.2451187e-20, 3.1946650e-18]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0hmnf5orki</td>\n",
       "      <td>274</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0bgj9co0zl</td>\n",
       "      <td>393</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03123sl42g</td>\n",
       "      <td>575</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0vwaki2su2</td>\n",
       "      <td>388</td>\n",
       "      <td>0.999985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09jgq862fk</td>\n",
       "      <td>832</td>\n",
       "      <td>0.999886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id      conf\n",
       "0  0hmnf5orki          274  0.999995\n",
       "1  0bgj9co0zl          393  0.999982\n",
       "2  03123sl42g          575  0.999996\n",
       "3  0vwaki2su2          388  0.999985\n",
       "4  09jgq862fk          832  0.999886"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_soft_voting = ((pred_2)+(pred_3)+ (pred_4)+ (2*pred_5) )/5\n",
    "pred_df = pd.DataFrame({'id':id_list,\n",
    "                   'landmark_id':np.argmax(pred_soft_voting,axis=1),\n",
    "                   'conf':np.max(pred_soft_voting,axis=1)})\n",
    "pred_df['id'] = pred_df['id'].apply(lambda x : x.numpy().decode('utf-8'))\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>landmark_id</th>\n",
       "      <th>conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xlf1tgh2ih</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68a3ot4osk</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>si2lek4u0a</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmtqxhipnv</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2flmjdud0e</td>\n",
       "      <td>956</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  landmark_id      conf\n",
       "0  xlf1tgh2ih          956  0.999995\n",
       "1  68a3ot4osk          956  0.999940\n",
       "2  si2lek4u0a          956  0.999940\n",
       "3  rmtqxhipnv          956  0.999850\n",
       "4  2flmjdud0e          956  0.999992"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = './public'\n",
    "submission = pd.read_csv(path + '/sample_submisstion.csv')\n",
    "sub = pd.merge(submission[['id']], pred_df, on='id', how='left')\n",
    "display(sub.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(path + '/Final_soft_voting_Weighted_model_3.csv', encoding='cp949', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = './public'\n",
    "train_tfrecord_path = path + '/tf_record_train.tfrecords'\n",
    "valid_tfrecord_path = path + '/tf_record_valid.tfrecords'\n",
    "\n",
    "BUFFER_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASS = 1049\n",
    "img_size = (270,480)\n",
    "with tf.device('/device:GPU:0'):\n",
    "    image_feature_description = {\n",
    "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "        'randmark_id': tf.io.FixedLenFeature([], tf.int64),\n",
    "        # 'id': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    def _parse_image_function(example_proto):\n",
    "        return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "    def map_func(target_record):\n",
    "        img = target_record['image_raw']\n",
    "        label = target_record['randmark_id']\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.dtypes.cast(img, tf.float32)\n",
    "        return img, label\n",
    "\n",
    "    def prep_func(image, label):\n",
    "        result_image = image / 255\n",
    "        result_image = tf.image.resize(result_image, img_size)\n",
    "\n",
    "        onehot_label = tf.one_hot(label, depth=NUM_CLASS)\n",
    "        return result_image, onehot_label\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(train_tfrecord_path, compression_type='GZIP')\n",
    "    dataset = dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    valid_dataset = tf.data.TFRecordDataset(valid_tfrecord_path, compression_type='GZIP')\n",
    "    valid_dataset = valid_dataset.map(_parse_image_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    valid_dataset = valid_dataset.map(map_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    valid_dataset = valid_dataset.batch(BATCH_SIZE)\n",
    "    valid_dataset = valid_dataset.map(prep_func, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    valid_dataset = valid_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "     \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551/551 [==============================] - 105s 190ms/step - loss: 0.0102 - accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model = load_model('./landmark_MobileNetv2_model_270_480_radam_2.h5', compile=False)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=Adam(learning_rate=0.0001),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    model.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = [98.27, 98.40, 98.45,98.93,98.47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19952489239015675\n",
      "0.19978884106229192\n",
      "0.19989035978234387\n",
      "0.20086493949484288\n",
      "0.19993096727036466\n"
     ]
    }
   ],
   "source": [
    "for i in list1:\n",
    "    print(i/sum(list1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_latest_p37] *",
   "language": "python",
   "name": "conda-env-tensorflow2_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
